:PROPERTIES:
:ID:       a1f67fe2-36ce-44aa-b027-14256be6022f
:END:
#+title: pandas_py

Manipulation de données tabulaires.

On peut créer un dictionnaire (1) puis l'importer avec pandas.

Il y a un peu de taffs en préambule du coté d'org https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-python.html !

#+name: pd2org
#+begin_src python :var df="df" :exports none
return f"return tabulate({df}, headers={df}.columns, tablefmt='orgtbl')"
#+end_src

#+RESULTS: pd2org
: return tabulate(df, headers=df.columns, tablefmt='orgtbl')

* Intro

** Avec un dictionnaire
#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+begin_src python
import pandas as pd
df = pd.DataFrame({
    "a": [1,2,3],
    "b": [4,5,6]
})
df.index = ["bill", "bob", "jim"]

<<pd2org("df")>>

#+end_src

#+RESULTS:
: |      |   a |   b |
: |------+-----+-----|
: | bill |   1 |   4 |
: | bob  |   2 |   5 |
: | jim  |   3 |   6 |


On passe un dictionnaire dans la fonction ~DataFrame()~.

Il est aussi possible de /set/ l'indice des lignes avec la methode ~index~

** via un CSV

Il y a la fonction ~pd.read_csv("path", index_col = 0)~

L'argument index_col est utilisé ici pour indiquer que la première ligne contient le header.

* Selecting/slicing

~DF["ma_colonne"]~ va renvoyer un /pandas series/ objet.

~DF[\["ma_colonne"]]~ va renvoyer un DataFrame (le \ est en trop)

On Peut indiquer plusieurs nom de colonne.

~DF[1:4]~ les lignes de 1 à 4 (sans prendre la première)

Si on veut avoir un truc similaire à R il faut utiliser:

- ~loc~ label based: les lables de chaques lignes (d'ou l'interet de la méthode index pour les nomer).

  ~DF.loc["index_ligne"]~ -> renvoie une serie pandas
  ~DF.loc[\["index_ligne"]]~ -> renvoie un DF

~DF.loc[["index1_l", "index2_l"], ["col1", "col2"]]~ permet de selectionner deux lignes et deux colonnes. On peut bien panacher ~DF.loc[:,["col2", "col3"]~

- ~iloc~ localisation basé sur un entier

  ~DF.iloc[[1,2,3],[0,1]]~

* Filtres

On peut vouloir sélectionner à l'aide de filtre comme: ~colonne > un_nombre~

comme pandas est construit sur [[numpy]] on peut utiliser les mêmes fonctions:

#+begin_src python
DF[np.logical_and(x == 'bill', y < 1.80)]
DF[np.logical_or(x == 'bob', y == 'bill')]
#+end_src

#+RESULTS:

* Itération

Une boucle /for/ classique sur un objet DF va se faire juste sur le noms de colonnes.

#+begin_src python :results value
import pandas as pd
path = "https://raw.githubusercontent.com/defuneste/utile_comme_du_pq/master/iris_dataset.csv"
iris = pd.read_csv(path, index_col = 0)

for lab, row in iris.iterrows() :
    print(row['target'])
# lab est le label de la ligne
# ici je n'ai utilisé que row
#+end_src

#+RESULTS:
: None

* Apply

#+begin_src python
DF["une_nouvelle_colonne"] = DF["une_colone"].apply(len)
# ic on applique leng sur "une colonne" et on sauve dans "une_nouvelle_colonne"
#+end_src

* I/O

** Flat files

~pd.read_csv()~ utilise des arguments pour limiter le nombre de colonnes:

- ~usecols~ : prend une liste de nom ou numéro de colonnes
- ~nrows~ : limite le nombre de lignes
- ~skiprows~ : prend une liste
- ~header~ : ~None~ pratique si on les skips
- ~names~ : une liste des noms de colonnes

#+header: :prologue from tabulate import tabulate
#+header: :noweb strip-export
#+begin_src python :results value
import pandas as pd
path = "https://raw.githubusercontent.com/defuneste/utile_comme_du_pq/master/iris_dataset.csv"
colnames = ["target", "sepal length (cm)"]
iris = pd.read_csv(path,
                   usecols = colnames)

iris_h = iris.head()

<<pd2org("iris_h")>>
#+end_src

#+RESULTS:
: |    |   sepal length (cm) | target      |
: |----+---------------------+-------------|
: |  0 |                 5.1 | Iris-setosa |
: |  1 |                 4.9 | Iris-setosa |
: |  2 |                 4.7 | Iris-setosa |
: |  3 |                 4.6 | Iris-setosa |
: |  4 |                 5   | Iris-setosa |

 - ~dtype~ : prends un dictionnaire (~{"pas_un_nombre" : str}~) avec le nom des colonnes et le type de données
 - ~na_values~ : prends, une valeur, une liste ou un dictionnaire. Dans le cas du dictionnaire il faut spécifier la colonne et la valeur qui devient NA.
   La methode ~isna()~ peut être utile : ~print(iris[iris.target.isma()])~
 - ~error_bad_lines=False~ ou ~warn_bad_lines=True~ permet de vérifier les erreurs dans un csv (trop de valeur/colonnes par ex)
 -
** Spreadsheets

Il faut se rappeler qu'il peut y avoir de nombreuses feuilles de calculs dans une seul document (argument: ~sheet_name~ pour spécifier le numéro ou sont nom). Si ~None~ est utilisée comme valeur toutes les feuilles sont lues dans un dictionnaire.

Les feuilles de calculs peuvent aussi contenir de la mise en formes.

On peut avoir des feuilles de calculs avec de nombreuses petites tables ou encore avec des entêtes.

La fonction principale de pandas est ~read_excel()~. On y retrouve des arguements de ~read_csv()~. En plus ~usecols~ peux prendre des strings propre aux tableurs comme "A:P".

** Connection via une [[id:5fe9773a-71d0-48bc-a083-c0a8d9941fe0][Databases]]

Pour [[python]] la bibliothèque est [[id:6558c7c6-3992-49d9-a270-1505651a9f65][sqlalchemy]].

Pour R c'est [[id:ed90188f-ff2f-447f-a66a-545252c5c474][DBI]].

La fonction ~pd.read_sql(query, engince)~ est utilisée. ~query~ correspond à la requête, du SQL encadré de "" et ~engine~ correspond à la connexions à la BD. ~query~ peut aussi être un nom de table ("ma_table").


* Date and times

Pas défaut Pandas sauve les dates en format /string/ (il y a de nombreux format pour encore ce type d' informations). Si on veut pouvoir travailler dessus il faut le "parser". Les fonctions d' import ont l' argument ~parse_dates~  et il peut une liste de colonne ou leurs nombres, une liste de listes et un dictionnaire.

Cependant ce arguments ne marche que si les chaînes de caractères ne sont pas trop horribles. Sinon il faut utiliser la fonction de pandas ~to_datetime()~. Elle prend un df avec une colonne à convertir. L'argument ~format~ avec la représentation de la date.
